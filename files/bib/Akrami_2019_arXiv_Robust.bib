@misc{Akrami_2019_arXiv_Robust,
    abstract = {Machine learning methods often need a large amount of labeled training data.Since the training data is assumed to be the ground truth, outliers can severelydegrade learned representations and performance of trained models. Here we applyconcepts from robust statistics to derive a novel variational autoencoder that isrobust to outliers in the training data. Variational autoencoders (VAEs) extract alower-dimensional encoded feature representation from which we can generatenew data samples. Robustness of autoencoders to outliers is critical for generatinga reliable representation of particular data types in the encoded space when usingcorrupted training data. Our robust VAE is based on beta-divergence rather than thestandard Kullback-Leibler (KL) divergence. Our proposed lower bound lead to aRVAE model that has the same computational complexity as the VAE and contains a single tuning parameter to control the degree of robustness. We demonstrate theperformance of our beta-divergence based autoencoder for a range of image datasets,showing improved robustness to outliers both qualitatively and quantitatively. Wealso illustrate the use of our robust VAE for outlier detection.},
    author = {Akrami, Haleh and Joshi, Anand A. and Li, Jian and Aydore, Sergul and Leahy, Richard M.},
    doi = {https://arxiv.org/abs/1905.09961},
    journal = {arXiv},
    title = {Robust variational autoencoder},
    year = {2019}
}

